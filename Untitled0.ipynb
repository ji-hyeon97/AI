{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGZOIQUS-bua",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3de27283-b74c-404d-a62b-160609e5b957"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "xy = np.loadtxt('/content/zoo.csv', delimiter=',', dtype = np.float32)#학습데이터 읽기\n",
        "x_data = xy[:, 0:-1]#처음부터 마지막 컬럼 전까지의 값\n",
        "y_data = xy[:, [-1]]#마지막 컬럼은 결과값\n",
        "nb_classes = 7 # 0~6 까지 7까지 분류를 합니다.\n",
        "X = tf.placeholder(tf.float32, [None, 16])#데이터들이 16 가지 특징을 가집니다.\n",
        "Y = tf.placeholder(tf.int32, shape=[None, 1])#데이터가 1개의 결과를 나타냅니다.\n",
        "Y_one_hot = tf.one_hot(Y,nb_classes)\n",
        "Y_one_hot = tf.reshape(Y_one_hot, [-1,nb_classes])\n",
        "W = tf.Variable(tf.random_normal([16, nb_classes]), name='weight')\n",
        "b = tf.Variable(tf.random_normal([nb_classes]), name='bias')\n",
        "# tf.nn.softmax computes softmax activations\n",
        "# softmax = exp(logits) / reduce_sum(exp(logits), dim)\n",
        "logits = tf.matmul(X, W) + b# logits 는 결과는 데이터\n",
        "hypothesis = tf.nn.softmax(tf.matmul(X, W) + b)# 결과데이터를 softmax 를 이용하여 합계가 1 이되도록 확률로 계산하도록 가설을 세운다.\n",
        "# Cross entropy cost/loss\n",
        "cost_i = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=Y_one_hot) \n",
        "cost = tf.reduce_mean(cost_i)\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)#cost값 최소화\n",
        "prediction = tf.argmax(hypothesis,1)#prediction값과\n",
        "correction_prediction = tf.equal(prediction,tf.argmax(Y_one_hot,1))#Y_one_hot값이 같은지 비교\n",
        "accuracy = tf.reduce_mean(tf.cast(correction_prediction, tf.float32))#정확도 나타냄\n",
        "# Launch graph\n",
        "with tf.Session() as sess:#학습\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    for step in range(2000):\n",
        "       sess.run(optimizer, feed_dict={X: x_data, Y: y_data})           \n",
        "       if step%100==0:\n",
        "         loss,acc = sess.run([cost, accuracy], feed_dict={X: x_data, Y: y_data})#엑셀데이터분류\n",
        "         print(\"Step: {:5} \\t Loss{:.3f}\\t Acc: {:.2%}\".format(step,loss,acc))\n",
        "    pred = sess.run(prediction,feed_dict={X: x_data})\n",
        "    for p,y in zip(pred, y_data.flatten()):#p는 앞, y는 뒤에꺼 처리\n",
        "      print(\"[{}] Prediction: {} True Y: {}\".format(p==int(y),p,int(y)))#결과(True,False),결과값,실제값\n",
        "   \n",
        "\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Step:     0 \t Loss3.172\t Acc: 0.00%\n",
            "Step:   100 \t Loss0.181\t Acc: 94.12%\n",
            "Step:   200 \t Loss0.087\t Acc: 100.00%\n",
            "Step:   300 \t Loss0.053\t Acc: 100.00%\n",
            "Step:   400 \t Loss0.037\t Acc: 100.00%\n",
            "Step:   500 \t Loss0.028\t Acc: 100.00%\n",
            "Step:   600 \t Loss0.023\t Acc: 100.00%\n",
            "Step:   700 \t Loss0.019\t Acc: 100.00%\n",
            "Step:   800 \t Loss0.016\t Acc: 100.00%\n",
            "Step:   900 \t Loss0.014\t Acc: 100.00%\n",
            "Step:  1000 \t Loss0.013\t Acc: 100.00%\n",
            "Step:  1100 \t Loss0.012\t Acc: 100.00%\n",
            "Step:  1200 \t Loss0.011\t Acc: 100.00%\n",
            "Step:  1300 \t Loss0.010\t Acc: 100.00%\n",
            "Step:  1400 \t Loss0.009\t Acc: 100.00%\n",
            "Step:  1500 \t Loss0.008\t Acc: 100.00%\n",
            "Step:  1600 \t Loss0.008\t Acc: 100.00%\n",
            "Step:  1700 \t Loss0.007\t Acc: 100.00%\n",
            "Step:  1800 \t Loss0.007\t Acc: 100.00%\n",
            "Step:  1900 \t Loss0.006\t Acc: 100.00%\n",
            "[True] Prediction: 0 True Y: 0\n",
            "[True] Prediction: 3 True Y: 3\n",
            "[True] Prediction: 0 True Y: 0\n",
            "[True] Prediction: 0 True Y: 0\n",
            "[True] Prediction: 0 True Y: 0\n",
            "[True] Prediction: 0 True Y: 0\n",
            "[True] Prediction: 3 True Y: 3\n",
            "[True] Prediction: 3 True Y: 3\n",
            "[True] Prediction: 0 True Y: 0\n",
            "[True] Prediction: 0 True Y: 0\n",
            "[True] Prediction: 1 True Y: 1\n",
            "[True] Prediction: 3 True Y: 3\n",
            "[True] Prediction: 6 True Y: 6\n",
            "[True] Prediction: 6 True Y: 6\n",
            "[True] Prediction: 6 True Y: 6\n",
            "[True] Prediction: 1 True Y: 1\n",
            "[True] Prediction: 0 True Y: 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFSFqis8Mvw1"
      },
      "source": [
        "# 새 섹션"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g06M1LhP-qQm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}